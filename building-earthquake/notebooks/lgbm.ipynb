{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cfdaacbc-23a3-423d-8d4d-120939ac7383",
    "_uuid": "7ac1e40a6d3a14f48e39f54297f50cd889bde493"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['damage_grade'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_damage_grade = preprocessing.LabelEncoder()\n",
    "train_df['damage_grade_enc'] = le_damage_grade.fit_transform(train_df['damage_grade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([train_df, test_df])\n",
    "print(all_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feat eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_df = pd.read_csv(\"../input/Building_Structure.csv\")\n",
    "structure_df.drop('district_id', axis=1, inplace=True)\n",
    "structure_df.drop('vdcmun_id', axis=1, inplace=True)\n",
    "structure_df.drop('ward_id', axis=1, inplace=True)\n",
    "\n",
    "ownership_df = pd.read_csv(\"../input/Building_Ownership_Use.csv\")\n",
    "ownership_df.drop('district_id', axis=1, inplace=True)\n",
    "ownership_df.drop('vdcmun_id', axis=1, inplace=True)\n",
    "ownership_df.drop('ward_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = all_df.merge(structure_df, how='left', on='building_id')\n",
    "all_df = all_df.merge(ownership_df, how='left', on='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in ['area_assesed', 'land_surface_condition', 'foundation_type', 'roof_type', 'ground_floor_type', 'other_floor_type', 'position', 'plan_configuration', 'condition_post_eq', 'legal_ownership_status']:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    all_df[label + '_enc'] = le.fit_transform(all_df[label])\n",
    "    all_df.drop(label, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.columns[[not np.issubdtype(dt, np.number) for dt in all_df.dtypes]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['other_floor_type_enc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "320b6de314d80d7038b0ec1d9a315a0b190b56e5"
   },
   "outputs": [],
   "source": [
    "numeric_features = all_df.columns[[np.issubdtype(dt, np.number) for dt in all_df.dtypes]]\n",
    "numeric_features = numeric_features.drop([\n",
    "    'damage_grade_enc'\n",
    "])\n",
    "\n",
    "numeric_features = numeric_features.drop([\n",
    "    'has_secondary_use_health_post',\n",
    "    'has_secondary_use_use_police',\n",
    "    'has_secondary_use_gov_office',\n",
    "    'has_secondary_use_school',\n",
    "    'has_secondary_use_industry',\n",
    "    'has_secondary_use_institution',\n",
    "    'has_geotechnical_risk_other',\n",
    "    'has_secondary_use_hotel',\n",
    "    'has_geotechnical_risk_liquefaction',\n",
    "    'has_geotechnical_risk_flood',\n",
    "    'has_secondary_use_rental'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = []\n",
    "cat_features.append(np.where(numeric_features.values == 'condition_post_eq_enc')[0][0])\n",
    "cat_features.append(np.where(numeric_features.values == 'area_assesed_enc')[0][0])\n",
    "cat_features.append(np.where(numeric_features.values == 'other_floor_type_enc')[0][0])\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = all_df[:631761]\n",
    "test_df = all_df[631761:]\n",
    "\n",
    "train_f_df = train_df[numeric_features]\n",
    "test_f_df = test_df[numeric_features]\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9baab72c129aa7823e036b978f99e00f753d19bd"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(train_f_df.as_matrix(), \n",
    "                                                      train_df['damage_grade_enc'].as_matrix(),\n",
    "                                                      test_size=0.20,\n",
    "                                                      random_state=42)\n",
    "\n",
    "print(type(train_X))\n",
    "print(type(valid_X))\n",
    "\n",
    "print(train_X.shape)\n",
    "print(valid_X.shape)                                           \n",
    "print(train_y.shape)\n",
    "print(valid_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(train_X, train_y)\n",
    "lgb_eval = lgb.Dataset(valid_X, valid_y, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM parameters\n",
    "params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'multiclass',\n",
    "        'metric': {'multi_error'},\n",
    "        'num_class': 5,\n",
    "        'learning_rate': 0.08,\n",
    "        'num_leaves': 64,\n",
    "        'min_data_in_leaf': 200,\n",
    "        'num_iteration': 2000,\n",
    "        'max_depth': 6,\n",
    "        'cat_feature': cat_features,\n",
    "        'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.train(params,\n",
    "            lgb_train,\n",
    "            valid_sets=lgb_eval,\n",
    "            early_stopping_rounds=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = gbm.predict(valid_X, num_iteration=gbm.best_iteration)\n",
    "y_predict = np.argmax(y_predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score as f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(valid_y, y_predict, average='weighted'))\n",
    "\n",
    "# 0.7617929010528087 0.72905\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_predict.flatten()).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criar CSV para submiss√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_f_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_f_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = gbm.predict(test_f_df.as_matrix(), num_iteration=gbm.best_iteration)\n",
    "y_predict = np.argmax(y_predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_dec = le_damage_grade.inverse_transform(y_predict.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_predict.flatten()).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_df = pd.DataFrame()\n",
    "\n",
    "sample_submission_df['building_id'] = test_df['building_id']\n",
    "sample_submission_df['damage_grade'] = y_predict_dec\n",
    "sample_submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 36,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
